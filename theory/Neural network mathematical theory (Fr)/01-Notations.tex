\subsection{Entiers}
	\begin{itemize}
		\item $p$: Nombre de couches (Autres que la couche d'entrée)\\
		\item $k, l$: Indices de couche, $k\in\nrange{0}{p}$, $l\in\nrange{0}{p}$\\
		      Couche d'entrée: $k = 0$\\
		      Couche de sortie: $k = p$\\
		\item $s_k$: Nombre de neurones de la couche $k$\\
	\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Réel}
$\alpha\in\R^{+*}$: Learning rate\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Matrices}
	\begin{itemize}
		\item $A^T$: La transposée de la matrice $A$\\
		\item $0_{n, m}$: La matrice $\R^{n\times m}$ ($n$ lignes et $m$ colonnes) ne contenant que des $0$\\
		\item $E^{n\times m}_{i,j}$: La matrice de $\R^{n\times m}$ dont le coefficient ligne $i$ colonne $j$ et un $1$, les autres étant des $0$\\
		
		\item $w^{(k)}\in\R^{s_{k+1}\times s_k}, k\in\nrange{0}{p-1}$: Poids pour passer de la couche $k$ à la couche $k+1$\\
					$w_{i, j}^{(k)}$: Coefficient ligne $i$ colonne $j$\\
					
					%\[\]
					
					%$W\triangleq \ens{w^{(k)}}{k\in\nrange{0}{p - 1}}$\\
					
					%\[\]
					
					On note $AB$ le produit matriciel usuel entre 2 matrices ou vecteurs $A$ et $B$ de tailles compatibles\\
					
					%\[\]
		
		\item $\left[a_{i, j}\right]_{\substack{i\in\nrange{1}{n}\\j\in\nrange{1}{m}}}$ désigne la matrice de $n$ lignes et $m$ colonnes dont le coefficient ligne $i$ colonne $j$ est $a_{i, j}$\\
	\end{itemize}
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
\subsection{Vecteurs}
	\begin{itemize}
		\item $0_{n}$: Le vecteur de $\R^n$  n'ayant que des $0$\\
		\item $E^{n}_i$: Le vecteur de $\R^n$ ayant un $1$ sur la $i$-ième ligne et des $0$ partout ailleurs\\
		
		\item $x\in\R^{s_0}$: Valeur d'entrée\\
			
		\item $y\in\R^{s_p}$: Valeur attendue\\
		
		\item $y_\text{pred}\in\R^{s_p}$: Valeur de sortie\\
		
		\item $b^{(k)}\in\R^{s_{k+1}}, k\in\nrange{0}{p-1}$: Biais pour passer de la couche $k$ à la couche $k+1$\\
	        $b_i^{(k)}$: Coefficient ligne $i$\\
					
			    %$B\triangleq \ens{b^{(k)}}{k\in\nrange{0}{p - 1}}$\\
					
		\item $z^{(k)}, k\in\nrange{1}{p}$: Valeurs des différents neurones de la couche $k$ avant activation\\
		      $z_i^{(k)}$: Coefficient ligne $i$, Valeur du $i$-ième neurone de la couche $k$ avant activation\\
					$z^{(0)}$ n'est pas défini\\
					$z^{(p)} = y_\text{pred}$\\
					
		\item $a^{(k)}, k\in\nrange{0}{p - 1}$: Valeurs des différents neurones de la couche $k$ après activation\\
		      $a_i^{(k)}$: Coefficient ligne $i$, Valeur du $i$-ième neurone de la couche $k$ après activation\\
					$a^{(0)} = x$\\
					$a^{(p)}$ n'est pas défini\\
	\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
\subsection{Fonctions}
	
	\begin{itemize}
		\item $diag$: Fonction qui à un vecteur $v$ de $\R^n$ associe la matrice de $\R^{n\times n}$ dont le coefficient ligne $i$ colonne $i$ est $v_i$ pour $i\in\nrange{1}{n}$ et tous les autres sont nuls\\
		
		\item $g:\R\rightarrow\R$: Fonction d'activation\\
		
		      On désigne également par $g$ l'application qui à un vecteur $u$ de $\R^{n}$ associe $[g(u_i)]_{i\in\nrange{1}{n}}$\\
					De même, $g'(u) = [g'(u_i)]_{i\in\nrange{1}{n}}$\\
					
		\item \[h_k: \fct{\R^{s_k}\times\R^{s_{k+1}\times s_k}\times\R^{s_k}}{\R^{s_{k+1}}}
								     {(b^{(k)}, w^{(k)}, a^{(k)})}{b^{(k)} + w^{(k)}a^{(k)}}\]
							
					$(k\in\nrange{0}{p - 1})$\\
					Fonction permettant de passer de $a^{(k)}$ à $z^{(k+1)}$\\
					
		\item $L: \R^{s_p}\rightarrow\left(\R^{s_p}\rightarrow\R^+\right)$: Fonction coût ayant pour paramètres la valeur attendue et la valeur prédite\\
		$L(y)$ est la fonction mesurant l'écart avec la valeur $y$\\
		
		\item $\tilde{L}_k (k\in\nrange{0}{p})$ : Fonction coût ayant pour paramètres:
			    \begin{itemize}
						\item[$\diamond$] $y$: la valeur attendue\\
						\item[$\diamond$] $\left(b^{(l)}_i\right)_{\substack{l\in\nrange{k}{p-1}\\
																									              {i\in\nrange{l}{s_{k+1}}}}}$\\
						\item[$\diamond$] $\left(w^{(l)}_{i, j}\right)_{\substack{l\in\nrange{k}{p-1}\\
																												{i\in\nrange{1}{s_{k+1}}}\\
																												{j\in\nrange{1}{s_k}}}}$\\
						\item[$\diamond$] $z^{(k)}$ si $k > 0$, $x$ sinon\\
					\end{itemize}
					
					\[\]
					
					Pour alléger les notations, ces paramètres seront simplement désignés par $(...)$\\

					
					\[\tilde{L}_p(y, y_\text{pred}) = L\left(y)(y_\text{pred}\right)\]
					
					\[\tilde{L}_{p - 1}(...) = L\left(
					                                  y, h_{p-1}\left(
					                                                    b^{(p-1)}, w^{(p-1)}, g\left(z^{(p-1)}
					                                                                           \right)
																												\right)
					                            \right)\]
					
					\[\tilde{L}_k(...) = L\left(
																	y, h_{p-1}\left(
																							b^{(p-1)}, w^{(p-1)}, g\circ h_{p-2}\left(
																																										b^{(p-2)}, w^{(p-2)}, g\circ h_{p-3}\left(...
																																																													b^{(k)}, w^{(k)}, g\left(z^{(k)}\right)
																																																													\right)
																																										\right)
																							\right)
														\right)\]
																				
					\[\tilde{L}_0(...) = L\left(
																	y, h_{p-1}\left(
																							b^{(p-1)}, w^{(p-1)}, g\circ h_{p-2}\left(
																																										b^{(p-2)}, w^{(p-2)}, g\circ h_{p-3}\left(...
																																																													b^{(0)}, w^{(0)}, x
																																																												\right)
																																										\right)
																							\right)
														\right)\]\\
	            
	\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
%\subsection{Dérivées directionelles}
	%On note $Df$ l'opérateur différentielle de la fonction $f$\\
	%
	%\begin{itemize}
		%\item $\pdv{\tilde{L}_k}{u}(...)\triangleq D\tilde{L}_k\left(...\right)(0,..., 0, u)$\\
		%
		%\item $\pdv{h_k}{u}(b, w, a)\triangleq Dh_k\left(b, w, a\right)(0_{s_{k+1}}, 0_{s_{k+1}, s_k}, u)$\\
		%
		%\item $\pdv{g}{u}(z) \triangleq Dg(z)(u)$\\
	%\end{itemize}